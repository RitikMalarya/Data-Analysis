{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/diamonds/diamonds.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('Unnamed: 0', axis=1, inplace=True)\ndata.columns = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'length', 'width', 'height']\ndata.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Preprocessing","metadata":{}},{"cell_type":"code","source":"\ndata.columns = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'length', 'width', 'height']\ndata.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(data[data[\"length\"]==0].index)\ndata = data.drop(data[data[\"width\"]==0].index)\ndata = data.drop(data[data[\"height\"]==0].index)\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_palette('coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(13,5))\nsns.histplot(data['carat'], kde=True, ax=ax[0], color='#21cc62')\nax[0].set_title('Distribution of carat')\nsns.boxplot(y=data['carat'], ax=ax[1], color='#21cc62')\nax[1].set_title('Distribution of carat')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = sns.countplot(x=data['cut'])\nplt.title('Distribution of cut')\nplt.show()\n\nfig = sns.countplot(x=data['color'])\nplt.title('Distribution of color')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(13,5))\nsns.histplot(data['height'], kde=True, ax=ax[0], color='#b51cd4')\nax[0].set_title('Distribution of height')\nsns.boxplot(y=data['height'], ax=ax[1], color='#b51cd4')\nax[1].set_title('Distribution of height')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(13,5))\nsns.histplot(data['length'], kde=True, ax=ax[0], color='#b51cd4')\nax[0].set_title('Distribution of length')\nsns.boxplot(y=data['length'], ax=ax[1], color='#b51cd4')\nax[1].set_title('Distribution of length')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There are clearly outliers to be seen depth, table, length, width and height columns.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"outlier_cols = ['depth', 'table', 'length', 'width', 'height']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_outliers = 0\n\nfor col in outlier_cols:  \n    print(f'\\nColumn Name: {col}')\n    \n    Q1 = np.percentile(data[col], 25, interpolation = 'midpoint')\n    Q3 = np.percentile(data[col], 75, interpolation = 'midpoint')\n    IQR = Q3 - Q1\n\n    print(f'Q1: {Q1} | Q2: {Q3} | IQR: {IQR}')\n    \n    upper_bound = Q3+1.5*IQR\n    lower_bound = Q1-1.5*IQR\n    print(f'upper bound: {upper_bound}')\n    print(f'lower bound: {lower_bound}')\n\n    # Upper bound\n    upper = data[data[col] >= upper_bound]\n    # Lower bound\n    lower = data[data[col] <= lower_bound]\n    \n    \n   \n    no_of_outliers = len(upper) + len(lower)\n    print(f\"Outliers Count :  {no_of_outliers}\\n\")\n    total_outliers += no_of_outliers\n    \n    # Remove Outlier\n    data = data[(data[col]<upper_bound) & (data[col]>lower_bound)]\n\n    print(f'{no_of_outliers} Outliers removed from {col} column.\\n')\n    \n    print(f'\\n\\nTotal outliers removed are {total_outliers}.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data shape\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport pickle\n\nlabel_data = data.copy()\n\ncut_label_encoder = LabelEncoder()\nlabel_data['cut'] = cut_label_encoder.fit_transform(label_data['cut'])\ncut_encoder = open('cut_encoder.pkl', 'wb')\npickle.dump(cut_label_encoder, cut_encoder)\ncut_encoder.close()\n\ncolor_label_encoder = LabelEncoder()\nlabel_data['color'] = color_label_encoder.fit_transform(label_data['color'])\ncolor_encoder = open('color_encoder.pkl', 'wb')\npickle.dump(color_label_encoder, color_encoder)\ncolor_encoder.close()\n\nclarity_label_encoder = LabelEncoder()\nlabel_data['clarity'] = clarity_label_encoder.fit_transform(label_data['clarity'])\n\nclarity_encoder = open('clarity_encoder.pkl', 'wb')\npickle.dump(clarity_label_encoder, clarity_encoder)\nclarity_encoder.close()\nlabel_data.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the Data","metadata":{}},{"cell_type":"code","source":"X = label_data.drop('price', axis=1)\ny = label_data['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear Regression\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import r2_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {'model_name':[], 'model':[], 'cv_score':[], 'accuracy':[]}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinear_regression = LinearRegression()\n#training\nlinear_regression.fit(X_train, y_train)\n#prediction\npredict_y = linear_regression.predict(X_test)\n\n\n#model cross validation score (negative root mean squared error)\ncv_score = cross_val_score(linear_regression, X_train, y_train, scoring='neg_root_mean_squared_error', cv=15).mean()\n\n#model accuracy on test data\naccuracy = round(r2_score(y_test, predict_y)*100,2)\n\n\nmodels['model_name'].append('Linear Regression')\nmodels['model'].append(linear_regression)\nmodels['model'].append(linear_regression)\nmodels['cv_score'].append(-cv_score)\nmodels['accuracy'].append(accuracy)\n\nprint('Model: Linear Regression')\nprint('Cross Validation Score: ', -cv_score)\nprint('Accuracy', accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decision Tree Regressor ","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndecision_tree_regression = DecisionTreeRegressor()\ndecision_tree_regression.fit(X_train, y_train)\n\npredict_y = decision_tree_regression.predict(X_test)\ncv_score = cross_val_score(decision_tree_regression, X_train, y_train, scoring='neg_root_mean_squared_error', cv=15).mean()\naccuracy = round(r2_score(y_test, predict_y)*100,2)\n\n\nmodels['model_name'].append('Decision Tree Regression')\nmodels['model'].append(decision_tree_regression)\nmodels['cv_score'].append(-cv_score)\nmodels['accuracy'].append(accuracy)\n\nprint('Model: Desision Tree Regression')\nprint('Cross Validation Score: ', -cv_score)\nprint('Accuracy', accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"SVM","metadata":{}},{"cell_type":"markdown","source":"Random Forest Regressor ","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\n#model\nsupport_vector_regression = SVR()\n#training\nsupport_vector_regression.fit(X_train, y_train)\n#prediction\npredict_y = support_vector_regression.predict(X_test)\n\n#model cross validation score (negative root mean squared error)\ncv_score = cross_val_score(support_vector_regression, X_train, y_train, scoring='neg_root_mean_squared_error', cv=15).mean()\n\n#model accuracy on test data\naccuracy = round(r2_score(y_test, predict_y)*100,2)\n\n\nmodels['model_name'].append('Support Vector Regression')\nmodels['model'].append(support_vector_regression)\nmodels['cv_score'].append(-cv_score)\nmodels['accuracy'].append(accuracy)\nprint('Model: Support Vector Regression')\nprint('Cross Validation Score: ', -cv_score)\nprint('Accuracy', accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Grading Boost Regressor ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n#model\ngradient_boosting_regression = GradientBoostingRegressor()\n#training\ngradient_boosting_regression.fit(X_train, y_train)\n#prediction\npredict_y = gradient_boosting_regression.predict(X_test)\n\n#model cross validation score (negative root mean squared error)\ncv_score = cross_val_score(gradient_boosting_regression, X_train, y_train, scoring='neg_root_mean_squared_error', cv=15).mean()\n\n#model accuracy on test data\naccuracy = round(r2_score(y_test, predict_y)*100,2)\n\n\nmodels['model_name'].append('Gradient Boosting Regression')\nmodels['model'].append(gradient_boosting_regression)\nmodels['cv_score'].append(-cv_score)\nmodels['accuracy'].append(accuracy)\n\n\n\nprint('Model: Gradient Boosting Regression')\nprint('Cross Validation Score: ', -cv_score)\nprint('Accuracy', accuracy)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,5))\nplots = sns.barplot(y=models['model_name'], x=models['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_output(input_val):\n    \n    output_val = []\n    \n    pkl_file = open('cut_encoder.pkl', 'rb')\n    cut_input_encoder = pickle.load(pkl_file) \n    pkl_file.close()\n\n    pkl_file = open('color_encoder.pkl', 'rb')\n    color_input_encoder = pickle.load(pkl_file) \n    pkl_file.close()\n\n    pkl_file = open('clarity_encoder.pkl', 'rb')\n    clarity_input_encoder = pickle.load(pkl_file) \n    pkl_file.close()\n\n    input_val[1] = cut_input_encoder.transform([input_val[1]])[0]\n    input_val[2] = color_input_encoder.transform([input_val[2]])[0] \n    input_val[3] = clarity_input_encoder.transform([input_val[3]])[0]\n    \n    for output_model_name,output_model in zip(models['model_name'],models['model']):\n        output_prediction = round(output_model.predict([input_val])[0],2)\n        print(f'{output_model_name} : {output_prediction}')\n        output_val.append(output_prediction)\n\n    fig = plt.figure(figsize=(12,5))\n    plots = sns.barplot(y=models['model_name'], x=output_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_val = [0.5, 'Fair', 'D', 'IF', 62.9, 56.8, 7.8, 45.8, 26.8]\n    \npredict_output(input_val)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}